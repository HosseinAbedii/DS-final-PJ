apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-consumer
  labels:
    app: spark-consumer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-consumer
  template:
    metadata:
      labels:
        app: spark-consumer
    spec:
      containers:
      - name: spark-consumer
        image: bitnami/spark:3.5.3
        command: ["/bin/bash", "-c"]
        args:
          - |
            pip install kafka-python pyspark requests numpy psutil &&
            spark-submit \
            --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3 \
            /app/consumer.py
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "mkdir -p /app/logs && chmod 777 /app/logs"]
        volumeMounts:
        - name: app-code
          mountPath: /app
        - name: log-volume
          mountPath: /app/logs
        env:
        - name: KAFKA_BROKER
          value: "kafka:9092"
        - name: SPARK_MASTER
          value: "spark://spark-master:7077"
      volumes:
      - name: app-code
        hostPath:
          path: /c/Users/abedi/OneDrive/Documents/GitHub/DS-final-PJ/src
      - name: log-volume
        hostPath:
          path: /c/Users/abedi/OneDrive/Documents/GitHub/DS-final-PJ/logs
---
apiVersion: v1
kind: Service
metadata:
  name: consumer-service
spec:
  selector:
    app: consumer
  ports:
    - protocol: TCP
      port: 5001  # Changed from 9092 to 5001
      targetPort: 5001  # Changed from 9092 to 5001
